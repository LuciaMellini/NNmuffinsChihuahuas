\section{Evaluation of the models}\label{3_evaluation}
In this section we evaluate the various neural networks according to their risk with respect to zero-one loss. We will estimate such measure using $5$-fold cross validation. We have chosen to round the predicted labels in $\left[0,1\right]$ to the nearest digit.

To have a broader view on the quality of the models we have carried out cross validation on the original dataset, formed by training, validation and test sets, and a dataset composed only by the training and test sets. In fact, seen that the validation set has been used to score the best hyperparameters for each of the models, one expects that the risk of the predictor would be higher seen that it has been calibrated on the validation set. 

We evaluate according to both the risk estimation versions the models obtained by setting the hyperparameters according to the best values extracted by training on the original dataset and the augmented one (see Section~\ref{hyperparameter_tuning}). All the results are gathered in Table~\ref{tab:riskEstimates}.

\input{tex/tables/riskEstimates}

\subsection{Original dataset}
In this section we look at the risk estimations found by carrying out $5$-fold cross validation on the original dataset, composed by the training, test and validation sets. 
\subsubsection{Without data augmentation}
We note that

\subsubsection{With data augmentation}

\subsection{Dataset without validation set}
In this section we look at the risk estimations found by carrying out $5$-fold cross validation on the images in the traning and test set. 
\subsubsection{Without data augmentation}
\subsubsection{With data augmentation}